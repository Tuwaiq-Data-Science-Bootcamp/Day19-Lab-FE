{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f4adb8",
   "metadata": {},
   "source": [
    "# Day19-Lab-FE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed5fe2",
   "metadata": {},
   "source": [
    "\n",
    "# 1 Label Encoding\n",
    "\n",
    "it converts the labels to numbers \n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Table1png.png) ![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/table2-1.png)\n",
    "\n",
    "\n",
    "## Challenges\n",
    "1. The data is ranked based on the alphabets, lead to the generation of priority issues.(hot-encoding)\n",
    "2. It assumes that data don't have an order, so it can't be used with Ordinal data.(ordinal encoding)\n",
    "\n",
    "### Label encoding is the best with Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ade1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "data['Country']= label_encoder.fit_transform(data['Country']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0c004",
   "metadata": {},
   "source": [
    "# 2 Ordinal Encoding \n",
    "\n",
    "used when the variables in the data have an order\n",
    "![image](https://miro.medium.com/max/640/1*QF5SZPFAQ7Y2qzV3aXW11A.png)\n",
    "![image](https://miro.medium.com/max/640/1*hciUJEYSMO6qz1xKLijUTA.png)\n",
    "\n",
    "## Assumptions\n",
    "it assumes order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68b6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder \n",
    "maplist = [{'col': 'satisfaction_rating', 'mapping': {'Very Dissatisfied': 0, 'Dissatisfied': 1,'Neutral': 2, 'Satisfied': 3, 'Very Satisfied': 4}}]\n",
    "oe = OrdinalEncoder(mapping=maplist)\n",
    "oe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecc287",
   "metadata": {},
   "source": [
    "# 3 One-Hot Encoding\n",
    "\n",
    "used for converting categorical variables to numerical by creates additional features based on the number of unique values in the categorical feature.\n",
    "\n",
    "![image](https://miro.medium.com/max/828/1*d5-PQyRRjvzBZjI5f7X3hA.png)\n",
    "\n",
    "##### it does'nt assume any order\n",
    "### Challenges\n",
    "\n",
    "1. one-hot encoder expand the dimensionality of the dataset\n",
    "2. Dummy Variable Trap (Multicollinearity)\n",
    "\n",
    "### Dummy Variable Encoding\n",
    "\n",
    "dropping one of the dummy variables\n",
    "\n",
    "![image](https://miro.medium.com/max/640/1*GlKVmFiao1DUFaxxu6Zucw.png)\n",
    "\n",
    "- “Red” color is encoded as [1 0] vector of size 2.\n",
    "- “Green” color is encoded as [0 1] vector of size 2.\n",
    "- “Blue” color is encoded as [0 0] vector of size 2.\n",
    "\n",
    " ### one-hot encoding is the good when The number of categorical features is less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories='auto', drop=None,sparse=False)\n",
    "\n",
    "ohe_df = pd.DataFrame(ohe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79148125",
   "metadata": {},
   "source": [
    "# 4 Target Mean Encoding\n",
    "\n",
    "replace a categorical value with the mean of the target variable.\n",
    "\n",
    "![image](https://miro.medium.com/max/828/1*8lK9mSxuPJ4b9SUXA3dN-A.png)\n",
    "\n",
    "### advantages \n",
    "\n",
    "1. it does not affect the volume of the data and helps in faster learning.\n",
    "2. it picks up values that can explain the target\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. may lead to overfitting ( feeding the features with information we are trying to model. This is like “cheating” since the model will learn from a variable that contains the target in itself)\n",
    "2. dataset-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "encoder = TargetEncoder()\n",
    "df['tempreture'] = encoder.fit_transform(df['tempreture'], df['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffc4d0",
   "metadata": {},
   "source": [
    "# 5 Frequency Encoding\n",
    "\n",
    "it encodes categorical feature values to their frequencies\n",
    "\n",
    "![image](https://miro.medium.com/max/786/1*l0mPlpqFEK_DSu4OqSnvLg.jpeg)\n",
    "\n",
    "### Limitations\n",
    "lose valuable information if there are two different categories with the same amount of observations count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c7555",
   "metadata": {},
   "source": [
    "# 6 Binary Encoding\n",
    "\n",
    "initially it ranks the categories then convert them into binary code\n",
    "\n",
    "![image](https://ithelp.ithome.com.tw/upload/images/20200905/20129584JJtMeWROIb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de399d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
